{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seeding for reproducibility**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "import numpy as np # type: ignore\n",
    "np.random.seed(0)\n",
    "\n",
    "import tensorflow as tf # type: ignore\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing the dependencies**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from zipfile import ZipFile\n",
    "from PIL import Image # type: ignore\n",
    "\n",
    "import numpy as np # type: ignore\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "import matplotlib.image as mpimg # type: ignore\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # type: ignore\n",
    "from tensorflow.keras import layers, models # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Curation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the kaggle.json file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle_credentails = json.load(open(\"kaggle.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # setup Kaggle API key as environment variables\n",
    "# os.environ['KAGGLE_USERNAME'] = kaggle_credentails[\"username\"]\n",
    "# os.environ['KAGGLE_KEY'] = kaggle_credentails[\"key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle datasets download -d abdallahalidev/plantvillage-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir(\"../test_images/plantvillage dataset\"))\n",
    "\n",
    "\n",
    "print(len(os.listdir(\"../test_images/plantvillage dataset/color\")))\n",
    "print(os.listdir(\"../test_images/plantvillage dataset/color\")[:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Number of Classes = 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(os.listdir(\"../test_images/plantvillage dataset/color/Potato___healthy\")))\n",
    "print(os.listdir(\"../test_images/plantvillage dataset/color/Potato___healthy\")[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Preprocessing**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Path\n",
    "base_dir = '../test_images/plantvillage dataset/color'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '../test_images/plantvillage dataset/color/Potato___Early_blight/0faca7fe-7254-4dfa-8388-bbc776338c9c___RS_Early.B 7929.JPG'\n",
    "\n",
    "# Read the image\n",
    "img = mpimg.imread(image_path)\n",
    "\n",
    "print(img.shape)\n",
    "# Display the image\n",
    "plt.imshow(img)\n",
    "plt.axis('off')  # Turn off axis numbers\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '../test_images/plantvillage dataset/color/Potato___Early_blight/0faca7fe-7254-4dfa-8388-bbc776338c9c___RS_Early.B 7929.JPG'\n",
    "\n",
    "# Read the image\n",
    "img = mpimg.imread(image_path)\n",
    "\n",
    "print(img) # We are printing the RGB value of each pixel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Parameters\n",
    "img_size = 256\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Data Generators\n",
    "data_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2  # Use 20% of data for validation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Generator\n",
    "train_generator = data_gen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    subset='training',\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Generator\n",
    "validation_generator = data_gen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    subset='validation',\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolutional Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)))\n",
    "model.add(layers.MaxPooling2D(2, 2))\n",
    "# We are adding more number of filters because as we go into more deeper layers the model should be able to find more complex and for that we would need more number of filters  \n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2, 2))\n",
    "\n",
    "\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(train_generator.num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,  # Number of steps per epoch\n",
    "    epochs=6,  # Number of epochs\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size  # Validation steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "print(\"Evaluating model...\")\n",
    "val_loss, val_accuracy = model.evaluate(validation_generator, steps=validation_generator.samples // batch_size)\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building a Predictive System**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Load and Preprocess the Image using Pillow\n",
    "def load_and_preprocess_image(image_path, target_size=(256, 256)):\n",
    "    # Load the image\n",
    "    img = Image.open(image_path)\n",
    "    # Resize the image\n",
    "    img = img.resize(target_size)\n",
    "    # Convert the image to a numpy array\n",
    "    img_array = np.array(img)\n",
    "    # Add batch dimension\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    # Scale the image values to [0, 1]\n",
    "    img_array = img_array.astype('float32') / 255.\n",
    "    return img_array\n",
    "\n",
    "# Function to Predict the Class of an Image\n",
    "def predict_image_class(model, image_path, class_indices):\n",
    "    preprocessed_img = load_and_preprocess_image(image_path)\n",
    "    predictions = model.predict(preprocessed_img)\n",
    "    predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
    "    predicted_class_name = class_indices[predicted_class_index]\n",
    "    return predicted_class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from class indices to class names\n",
    "class_indices = {v: k for k, v in train_generator.class_indices.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the class names as json file\n",
    "json.dump(class_indices, open('class_indices.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage\n",
    "image_path = '../test_images/plantvillage dataset/color/Potato___healthy/0b3e5032-8ae8-49ac-8157-a1cac3df01dd___RS_HL 1817.JPG'\n",
    "predicted_class_name = predict_image_class(model, image_path, class_indices)\n",
    "\n",
    "# Output the result\n",
    "print(\"Predicted Class Name:\", predicted_class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the model to Google drive or local**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('plant_disease_prediction_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
